s04q45 = ifelse(s04q45==0.1, median_s04q45, s04q45))%>%
select(-Q1, -Q3, -seuilmax, -seuilmin,-median_s04q45)
summary(Final_data$s04q45)
# IDENTIFICATION DES VALEURS ABERRANTES pour la variable "Avantages associés à l'emploi principal"
Final_data <- Final_data %>%
group_by(s04q29d) %>%
mutate(
Q1 = quantile(s04q47, 0.25, na.rm = TRUE),
Q3 = quantile(s04q47, 0.75, na.rm = TRUE),
seuilmax = min(max(s04q47, na.rm = TRUE), Q3 + 1.5 * (Q3 - Q1)),
seuilmin = max(min(s04q47, na.rm = TRUE), Q1 - 1.8 * (Q3 - Q1))
) %>%
mutate(
s04q47 = ifelse(s04q47 > seuilmax | s04q47 < seuilmin , 0.1, s04q47)
)
Final_data <- Final_data %>% group_by(s04q29d) %>%
mutate(median_s04q47 = median(s04q47[s04q47 != 0.1], na.rm = TRUE),
s04q47 = ifelse(s04q47==0.1, median_s04q47, s04q47))%>%
select(-Q1, -Q3, -seuilmax, -seuilmin,-median_s04q47)
summary(Final_data$s04q47)
# Calculons la somme des revenus provenant de l'emploi
Final_data <- Final_data %>%
rowwise() %>%
mutate(revenu_emploi = sum(c_across(starts_with("s04q4") | starts_with("s04q6")), na.rm = TRUE))
label(Final_data$revenu_emploi) <- "Total des revenus annuels issus des emplois pour les 12 derniers mois"
Section_1_data == 9999
Final_data == 9999
Final_data <- s00_me_SEN2018 %>%
left_join(housing_data, by = c("grappe", "menage"))%>%
left_join(Caract_socio_demo, by = c("grappe", "menage"))%>%
left_join(employment_data2, by = c("grappe", "menage", "s01q00a"))%>%
left_join(non_wage_income_data, by = c("grappe", "menage", "s01q00a"))%>%
left_join(education_data, by = c("grappe", "menage", "s01q00a"))
View(Final_data)
sapply(Final_data, function(x) sum(is.na(x)))
Final_data[Final_data == 9999] <- NA
sapply(Final_data, function(x) sum(is.na(x)))
install.packages("esquisse")
library(esquisse)
esquisser(employment_data)
esquisser(Final_data)
Final_data <- Final_data %>%
mutate(niveau_instr = s01q25) %>%
filter(!is.na(niveau_instr))
group_by(niveau_instr) %>%
summarise(count = n()) %>%
mutate(niveau = recode(niveau_instr,
"1" = "Aucun",
"2" = "Primaire",
"3" = "Secondaire 1er cycle",
"4" = "Secondaire 2nd cycle",
"5" = "Supérieur",
"6" = "NSP"))
instruction_levels <- Final_data %>%
group_by(niveau_instr) %>%
summarise(count = n()) %>%
mutate(niveau = recode(niveau_instr,
"1" = "Aucun",
"2" = "Primaire",
"3" = "Secondaire 1er cycle",
"4" = "Secondaire 2nd cycle",
"5" = "Supérieur",
"6" = "NSP"))
ggplot(instruction_levels, aes(x = niveau, y = count, fill = niveau)) +
geom_bar(stat = "identity") +
labs(title = "Niveau d'instruction le plus élevé atteint par le père",
x = "Niveau d'instruction",
y = "Nombre d'observations",
fill = "Niveau d'instruction") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
install.packages("ggplot2")
ggplot(instruction_levels, aes(x = niveau, y = count, fill = niveau)) +
geom_bar(stat = "identity") +
labs(title = "Niveau d'instruction le plus élevé atteint par le père",
x = "Niveau d'instruction",
y = "Nombre d'observations",
fill = "Niveau d'instruction") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(ggplot2)
ggplot(instruction_levels, aes(x = niveau, y = count, fill = niveau)) +
geom_bar(stat = "identity") +
labs(title = "Niveau d'instruction le plus élevé atteint par le père",
x = "Niveau d'instruction",
y = "Nombre d'observations",
fill = "Niveau d'instruction") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(readxl)
RATIOS2 <- read_excel("E:/ISEP 2/MON DOSSIER/APPRENTISSAGE DES VACANCES/DOCUMENTS DE STAGE/ECRITURE DE MON RAPPORT DE STAGE/MEMOIRE PROPREMENT DIT/BASE DE DONNEES/BASE A FUSIONNER 2/RATIOS2.xlsx")
View(RATIOS2)
summary(RATIOS2)
# Extraire les colonnes numériques uniquement
RATIOS2_numeric <- RATIOS2 %>% select(where(is.numeric))
correlation_matrix <- cor(RRATIOS2, use = "complete.obs") # Ignorer les valeurs manquantes
# Calcul de la matrice de corrélation
correlation_matrix <- cor(RATIOS2, use = "complete.obs") # Ignorer les valeurs manquantes
print(correlation_matrix)
install.packages("ggcorrplot")
library(ggcorrplot)
# Visualisation avec ggcorrplot
ggcorrplot(correlation_matrix, lab = TRUE, lab_size = 3)
# Visualiser la matrice de corrélation à l'aide de ggcorrplot
ggcorrplot(correlation_matrix,
lab = TRUE,       # Afficher les valeurs de corrélation sur la carte
lab_size = 3,     # Taille des labels
colors = c("red", "white", "blue"), # Choix des couleurs pour la carte
title = "Matrice de Corrélation des Ratios",  # Titre du graphique
hc.order = TRUE)  # Option pour réorganiser les variables par hiérarchie
# Standardiser les variables (si ce n'est pas déjà fait)
RATIOS2_scaled <- scale(RATIOS2)
# Réaliser l'ACP
pca <- prcomp(RATIOS2_scaled, center = TRUE, scale. = TRUE)
# Calculer les valeurs propres
eigenvalues <- pca$sdev^2
# Calculer la variance expliquée et la variance cumulative
explained_variance <- eigenvalues / sum(eigenvalues)  # Proportion de variance expliquée
cumulative_variance <- cumsum(explained_variance)  # Variance cumulative
# Créer un tableau des résultats
pca_summary <- data.frame(
Composante = 1:length(eigenvalues),
Valeur_propre = eigenvalues,
Variance_expliquee = explained_variance,
Variance_cumulative = cumulative_variance
)
# Afficher le tableau des résultats
print(pca_summary)
# Graphique de la variance expliquée par chaque composante
library(ggplot2)
ggplot(pca_summary, aes(x = Composante, y = Variance_expliquee)) +
geom_bar(stat = "identity", fill = "lightblue") +
labs(title = "Variance expliquée par chaque composante",
x = "Composante Principale",
y = "Proportion de Variance Expliquée") +
theme_minimal()
# Contributions des variables aux axes principaux
contributions <- pca$rotation^2  # Contribution au carré pour chaque variable et chaque composante
# Convertir en tableau
contributions_df <- as.data.frame(contributions)
contributions_df$Variable <- rownames(contributions_df)
# Afficher les contributions des variables aux axes
print(contributions_df)
# Graphique des contributions des variables à la première composante principale
ggplot(contributions_df, aes(x = reorder(Variable, -PC1), y = PC1)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Contributions des variables à la 1ère composante principale",
x = "Variable", y = "Contribution à la 1ère composante") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
theme_minimal()
# Graphique des contributions des variables à la deuxième composante principale
ggplot(contributions_df, aes(x = reorder(Variable, -PC2), y = PC2)) +
geom_bar(stat = "identity", fill = "salmon") +
labs(title = "Contributions des variables à la 2ème composante principale",
x = "Variable", y = "Contribution à la 2ème composante") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
theme_minimal()
n <- 10
sum_formula <- paste0("\\sum_{i=1}^{", n, "} i = ", n * (n + 1) / 2)
cat("$$", sum_formula, "$$")
valeurs <- c(4, 8, 15, 16, 23, 42)
moyenne <- mean(valeurs)
cat("$$\\bar{x} = ", moyenne, "$$")
valeurs <- c(4, 8, 15, 16, 23, 42)
moyenne <- mean(valeurs)
cat("la moyenne est ", moyenne.)
valeurs <- c(4, 8, 15, 16, 23, 42)
moyenne <- mean(valeurs)
cat("la moyenne est ", moyenne, ".")
# Définir les valeurs
m <- 2 # masse en kg
c <- 3e8 # vitesse de la lumière en m/s
E <- m * c^2
# Afficher la formule avec le résultat calculé
cat("La formule de la théorie de la relativité est : \n")
cat("$$E = mc^2$$\n")
cat(sprintf("En remplaçant m = %d kg et c = %.1e m/s, on obtient :\n", m, c))
cat(sprintf("$$E = %d \\times (%.1e)^2 = %.2e \\, J.$$", m, c, E))
valeurs <- c(4, 8, 15, 16, 23, 42)
moyenne <- mean(valeurs)
cat("La moyenne est $\\bar{x} = ", moyenne, "$.\n")
# Définir les valeurs
m <- 2 # masse en kg
c <- 3e8 # vitesse de la lumière en m/s
E <- m * c^2
# Afficher la formule avec le résultat calculé
cat("La formule de la théorie de la relativité est : \n")
cat("$$E = mc^2$$\n")
cat(sprintf("En remplaçant m = %d kg et c = %.1e m/s, on obtient :\n", m, c))
cat(sprintf("$$E = %d \\times (%.1e)^2 = %.2e \\, J.$$", m, c, E))
history(max.show = Inf)  # Affiche tout l'historique de la session
savehistory("recovered_script.R")  # Sauvegarde dans un fichier
# Dans la console R
file.edit("~/.Rhistory")  # Affiche l'historique des commandes
history(max.show = Inf)
install.packages("sdcMicro")
library (sdcMicro, readxl, tidyverse, haven)
library (sdcMicro)
library (readxl)
library (tidyverse)
library(haven)
sdcApp()
library (sdcMicro)
install.packages("sdcMicro")
library(sdcMicro)
sdcApp()
library(future)
library(future.apply)
# Définir un plan d’exécution parallèle
plan(multisession)
# Exécuter une opération en parallèle
resultats <- future_lapply(1:10, function(x) sqrt(x))
# Afficher les résultats
print(resultats)
library(parallel)
library(tictoc)
# Fonction séquentielle
tache_sequentielle <- function(n = 1e4) {
sum((1:n)^2)
}
# Fonction parallèle
tache_parallele <- function(n = 1e4, coeurs = 2) {
cl <- makeCluster(coeurs)  # Création d'un cluster de travail avec un nombre spécifié de cœurs
clusterExport(cl, varlist = "n")  # Exporter la variable 'n' dans les processus du cluster
resultat <- parLapply(cl, split(1:n, cut(1:n, coeurs)), function(x) sum(x^2))  # Calcul parallèle des carrés, chaque sous-ensemble 'x' est traité sur un cœur
stopCluster(cl)  # Arrêter le cluster une fois le calcul terminé
Reduce("+", resultat)  # Agréger les résultats obtenus sur les différents cœurs
}
# Liste des cœurs à tester
liste_coeurs <- c(1, 2, 3, 4, 5, 6, 8)
# Initialisation du tableau des résultats
resultats_simples <- data.frame(Cœurs = liste_coeurs, Temps = NA, Speedup = NA)
# Temps de référence (séquentiel)
temps_seq <- system.time(tache_sequentielle())[3]
# Remplissage du tableau
for (i in seq_along(liste_coeurs)) {
nb_coeurs <- liste_coeurs[i]
if (nb_coeurs == 1) {
resultats_simples$Temps[i] <- round(temps_seq, 4)
resultats_simples$Speedup[i] <- 1
} else {
temps_par <- system.time(tache_parallele(1e4, nb_coeurs))[3]
resultats_simples$Temps[i] <- round(temps_par, 4)
resultats_simples$Speedup[i] <- round(temps_seq / temps_par, 2)
}
}
# Affichage du tableau final
resultats_simples
setwd("E:/ISEP 2/MON DOSSIER/APPRENTISSAGE DES VACANCES/ISEP3/ME _ SEMESTRE 2/Calcul_parall-le_surR_T6/Bookdown/Calcul_Parallele_R")
bookdown::render_book("Page_de_garde.Rmd", "bookdown::gitbook")
setwd("E:/ISEP 2/MON DOSSIER/APPRENTISSAGE DES VACANCES/ISEP3/ME _ SEMESTRE 2/PROJET STATISTIQUE SOUS R ET PYTHON/GITHUB EXPOSE/Calcul_parall-le_surR_T6/Bookdown/Calcul_Parallele_R")
bookdown::render_book("Page_de_garde.Rmd", "bookdown::gitbook")
library(parallel)
library(tictoc)
# Fonction séquentielle
tache_sequentielle <- function(n = 1e4) {
sum((1:n)^2)
}
# Fonction parallèle
tache_parallele <- function(n = 1e4, coeurs = 2) {
cl <- makeCluster(coeurs)  # Création d'un cluster de travail avec un nombre spécifié de cœurs
clusterExport(cl, varlist = "n")  # Exporter la variable 'n' dans les processus du cluster
resultat <- parLapply(cl, split(1:n, cut(1:n, coeurs)), function(x) sum(x^2))  # Calcul parallèle des carrés, chaque sous-ensemble 'x' est traité sur un cœur
stopCluster(cl)  # Arrêter le cluster une fois le calcul terminé
Reduce("+", resultat)  # Agréger les résultats obtenus sur les différents cœurs
}
# Liste des cœurs à tester
liste_coeurs <- c(1, 2, 3, 4, 5, 6, 8)
# Initialisation du tableau des résultats
resultats_simples <- data.frame(Cœurs = liste_coeurs, Temps = NA, Speedup = NA)
# Temps de référence (séquentiel)
temps_seq <- system.time(tache_sequentielle())[3]
# Remplissage du tableau
for (i in seq_along(liste_coeurs)) {
nb_coeurs <- liste_coeurs[i]
if (nb_coeurs == 1) {
resultats_simples$Temps[i] <- round(temps_seq, 4)
resultats_simples$Speedup[i] <- 1
} else {
temps_par <- system.time(tache_parallele(1e4, nb_coeurs))[3]
resultats_simples$Temps[i] <- round(temps_par, 4)
resultats_simples$Speedup[i] <- round(temps_seq / temps_par, 2)
}
}
# Affichage du tableau final
resultats_simples
library(parallel)
library(tictoc)
# Fonction pour multiplier une sous-matrice (partie d'une matrice)
multiplication_matrice <- function(A, B, lignes, colonnes) {
res <- matrix(0, nrow = length(lignes), ncol = length(colonnes))
for (i in seq_along(lignes)) {
for (j in seq_along(colonnes)) {
res[i, j] <- sum(A[lignes[i], ] * B[, colonnes[j]])  # Produit scalaire des lignes et colonnes
}
}
return(res)
}
# Fonction principale pour multiplier deux grandes matrices en parallèle
calcul_multiplication_parallele <- function(A, B, sections = 4) {
n <- nrow(A)
# Diviser les lignes et colonnes en sous-ensembles équilibrés
lignes_par_section <- split(1:n, cut(1:n, sections, labels = FALSE))
colonnes_par_section <- split(1:n, cut(1:n, sections, labels = FALSE))
# Créer un cluster
cl <- makeCluster(detectCores())  # Utilise tous les cœurs disponibles
clusterExport(cl, varlist = c("A", "B", "multiplication_matrice"))  # Exporte seulement les variables nécessaires
# Paralléliser la multiplication
resultats <- parLapply(cl, 1:sections, function(i) {
lignes <- lignes_par_section[[i]]
colonnes <- colonnes_par_section[[i]]
multiplication_matrice(A, B, lignes, colonnes)
})
stopCluster(cl)
# Combiner les résultats dans la matrice finale
matrice_resultat <- matrix(0, nrow = n, ncol = n)
for (i in 1:sections) {
lignes <- lignes_par_section[[i]]
colonnes <- colonnes_par_section[[i]]
matrice_resultat[lignes, colonnes] <- resultats[[i]]
}
return(matrice_resultat)
}
# Créer deux grandes matrices de taille 1000x1000
set.seed(123)
A <- matrix(rnorm(1000^2), nrow = 1000, ncol = 1000)
B <- matrix(rnorm(1000^2), nrow = 1000, ncol = 1000)
# Liste des sections et cores à tester
liste_coeurs <- c(1, 2, 3, 4, 5, 6, 8)
resultats_multiplication <- data.frame(Cœurs = liste_coeurs, Temps = NA, Speedup = NA)
# Calcul séquentiel de référence (temps pour la multiplication sans parallélisme)
temps_seq <- system.time({
res_seq <- multiplication_matrice(A, B, 1:nrow(A), 1:ncol(B))
})[3]
# Remplissage du tableau des résultats
for (i in seq_along(liste_coeurs)) {
nb_coeurs <- liste_coeurs[i]
if (nb_coeurs == 1) {
resultats_multiplication$Temps[i] <- round(temps_seq, 4)
resultats_multiplication$Speedup[i] <- 1
} else {
temps_par <- system.time(calcul_multiplication_parallele(A, B, sections = nb_coeurs))[3]
resultats_multiplication$Temps[i] <- round(temps_par, 4)
resultats_multiplication$Speedup[i] <- round(temps_seq / temps_par, 2)
}
}
# Affichage uniquement du tableau récapitulatif des résultats
print(resultats_multiplication)
# Données des résultats
cœurs <- c(1, 2, 3, 4, 5, 6, 8)
speedup <- c(1.00, 2.55, 3.05, 3.49, 4.07, 4.17, 4.74)
# Calcul de l'efficacité
efficacité <- speedup / cœurs
# Tracer la courbe d'efficacité
plot(cœurs, efficacité, type = "b", col = "blue", pch = 16, xlab = "Nombre de cœurs", ylab = "Efficacité",
main = "Courbe d'efficacité en fonction du nombre de cœurs")
grid()
library(parallel)
library(tictoc)
# Fonction pour multiplier une sous-matrice (partie d'une matrice)
multiplication_matrice <- function(A, B, lignes, colonnes) {
res <- matrix(0, nrow = length(lignes), ncol = length(colonnes))
for (i in seq_along(lignes)) {
for (j in seq_along(colonnes)) {
res[i, j] <- sum(A[lignes[i], ] * B[, colonnes[j]])  # Produit scalaire des lignes et colonnes
}
}
return(res)
}
# Fonction principale pour multiplier deux grandes matrices en parallèle
calcul_multiplication_parallele <- function(A, B, sections = 4) {
n <- nrow(A)
# Diviser les lignes et colonnes en sous-ensembles équilibrés
lignes_par_section <- split(1:n, cut(1:n, sections, labels = FALSE))
colonnes_par_section <- split(1:n, cut(1:n, sections, labels = FALSE))
# Créer un cluster
cl <- makeCluster(nb_coeurs)
clusterExport(cl, varlist = c("A", "B", "multiplication_matrice"))  # Exporte seulement les variables nécessaires
# Paralléliser la multiplication
resultats <- parLapply(cl, 1:sections, function(i) {
lignes <- lignes_par_section[[i]]
colonnes <- colonnes_par_section[[i]]
multiplication_matrice(A, B, lignes, colonnes)
})
stopCluster(cl)
# Combiner les résultats dans la matrice finale
matrice_resultat <- matrix(0, nrow = n, ncol = n)
for (i in 1:sections) {
lignes <- lignes_par_section[[i]]
colonnes <- colonnes_par_section[[i]]
matrice_resultat[lignes, colonnes] <- resultats[[i]]
}
return(matrice_resultat)
}
# Créer deux grandes matrices de taille 1000x1000
set.seed(123)
A <- matrix(rnorm(1000^2), nrow = 1000, ncol = 1000)
B <- matrix(rnorm(1000^2), nrow = 1000, ncol = 1000)
# Liste des sections et cores à tester
liste_coeurs <- c(1, 2, 3, 4, 5, 6, 8)
resultats_multiplication <- data.frame(Cœurs = liste_coeurs, Temps = NA, Speedup = NA)
# Calcul séquentiel de référence (temps pour la multiplication sans parallélisme)
temps_seq <- system.time({
res_seq <- multiplication_matrice(A, B, 1:nrow(A), 1:ncol(B))
})[3]
# Remplissage du tableau des résultats
for (i in seq_along(liste_coeurs)) {
nb_coeurs <- liste_coeurs[i]
if (nb_coeurs == 1) {
resultats_multiplication$Temps[i] <- round(temps_seq, 4)
resultats_multiplication$Speedup[i] <- 1
} else {
temps_par <- system.time(calcul_multiplication_parallele(A, B, sections = nb_coeurs))[3]
resultats_multiplication$Temps[i] <- round(temps_par, 4)
resultats_multiplication$Speedup[i] <- round(temps_seq / temps_par, 2)
}
}
# Affichage uniquement du tableau récapitulatif des résultats
print(resultats_multiplication)
# Fonction principale pour multiplier deux grandes matrices en parallèle
calcul_multiplication_parallele <- function(A, B, nb_coeurs = 4) {
n <- nrow(A)
# Diviser les lignes et colonnes en sous-ensembles équilibrés
lignes_par_section <- split(1:n, cut(1:n, nb_coeurs, labels = FALSE))
colonnes_par_section <- split(1:n, cut(1:n, nb_coeurs, labels = FALSE))
# Créer un cluster
cl <- makeCluster(nb_coeurs)
clusterExport(cl, varlist = c("A", "B", "multiplication_matrice"))  # Exporte les variables nécessaires
# Paralléliser la multiplication
resultats <- parLapply(cl, 1:nb_coeurs, function(i) {
lignes <- lignes_par_section[[i]]
colonnes <- colonnes_par_section[[i]]
multiplication_matrice(A, B, lignes, colonnes)
})
stopCluster(cl)
# Combiner les résultats dans la matrice finale
matrice_resultat <- matrix(0, nrow = n, ncol = n)
for (i in 1:nb_coeurs) {
lignes <- lignes_par_section[[i]]
colonnes <- colonnes_par_section[[i]]
matrice_resultat[lignes, colonnes] <- resultats[[i]]
}
return(matrice_resultat)
}
# Fonction principale pour multiplier deux grandes matrices en parallèle
calcul_multiplication_parallele <- function(A, B, nb_coeurs = 4) {
n <- nrow(A)
# Diviser les lignes et colonnes en sous-ensembles équilibrés
lignes_par_section <- split(1:n, cut(1:n, nb_coeurs, labels = FALSE))
colonnes_par_section <- split(1:n, cut(1:n, nb_coeurs, labels = FALSE))
# Créer un cluster
cl <- makeCluster(nb_coeurs)
clusterExport(cl, varlist = c("A", "B", "multiplication_matrice"))  # Exporte les variables nécessaires
# Paralléliser la multiplication
resultats <- parLapply(cl, 1:nb_coeurs, function(i) {
lignes <- lignes_par_section[[i]]
colonnes <- colonnes_par_section[[i]]
multiplication_matrice(A, B, lignes, colonnes)
})
stopCluster(cl)
# Combiner les résultats dans la matrice finale
matrice_resultat <- matrix(0, nrow = n, ncol = n)
for (i in 1:nb_coeurs) {
lignes <- lignes_par_section[[i]]
colonnes <- colonnes_par_section[[i]]
matrice_resultat[lignes, colonnes] <- resultats[[i]]
}
return(matrice_resultat)
}
temps_par <- system.time(calcul_multiplication_parallele(A, B, nb_coeurs = nb_coeurs))[3]
bookdown::render_book("Page_de_garde.Rmd", "bookdown::gitbook")
bookdown::render_book("Page_de_garde.Rmd", "bookdown::gitbook")
bookdown::render_book("Page_de_garde.Rmd", "bookdown::gitbook")
bookdown::render_book("Page_de_garde.Rmd", "bookdown::gitbook")
tictoc::tic.clearlog()    # Nettoyage des logs de tictoc
### Chargement des librairies nécessaires
library(parallel)         # Pour créer et gérer un cluster de workers
library(dplyr)            # Pour la manipulation de données
library(tictoc)           # Pour mesurer les temps d'exécution
### 1- Génération de l'échantillon
# Ceci permet la reproductibilité pour que lors de la reexecution ca ressorte les meme valeurs
set.seed(42)
# Création d'un vecteur de 20 valeurs aléatoires
echantillon <- rnorm(n = 20, mean = 50, sd = 10)
# Affichage des valeurs
print(echantillon)
### 2- Calcul parallèle
# 2.1 Démarrage du chronomètre pour la phase parallèle
tic("Parallèle")  # "Parallèle est juste le nom du chronomètre lancé
# 2.2 Création d'un cluster de 2 workers
cluster <- makeCluster(2)
# 2.3 Division de l'échantillon en 2 sous-ensembles égaux
groupes <- split(echantillon, rep(1:2, each = 10))
# 2.4 Fonction de calcul de la moyenne (celle qui sera appliquée par chaque worker)
calcul_moyenne <- function(x) {
mean(x)
}
# 2.5 Export des objets et fonction vers les workers
clusterExport(cluster, varlist = c("groupes", "calcul_moyenne"), envir = environment()) # Environnement sert à indiquer que les données se trouve dans l'environnement actuel
# 2.6 Exécution parallèle : chaque worker calcule la moyenne de son sous-ensemble
moyennes_partielles <- parLapply(cluster, groupes, calcul_moyenne) # Remember, parLapply prend le nom du cluster, les groupes et la fonction à appliquer
# 2.7 Arrêt du cluster
tic.stop <- toc(log = TRUE) # Qui renvoie le temps executé par le chronomètre et stocke sa valeur
stopCluster(cluster)
# 2.8 Affichage des moyennes calculées par chaque worker
names(moyennes_partielles) <- paste0("Cœur_", seq_along(moyennes_partielles)) # Juste pour numeroter les coeur et avoir coeur_1 et coeur_2
print(moyennes_partielles)
# 2.9 Calcul de la moyenne agrégée finale (moyenne des moyennes)
moyenne_parallele <- mean(unlist(moyennes_partielles))
print(paste("Moyenne agrégée (parallèle) :", round(moyenne_parallele, 4)))
detectCores(logical = TRUE)
detectCores()
