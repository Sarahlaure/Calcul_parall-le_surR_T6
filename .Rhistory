clusterExport(cl, c("tri_fusion_par", "fusion"))
return(cl)
}
# Ex√©cution
set.seed(123)
donnees <- sample(1:100000, 50000) # 50 000 √©l√©ments
cl <- initialiser_cluster()
resultat <- tri_fusion_par(donnees, cl)
# T√¢che principale : additionner quatre vecteurs de 1e6 nombres
vec_list <- list(rnorm(1e6), rnorm(1e6), rnorm(1e6), rnorm(1e6))
# Fork-Join
n_cores <- 4
cl <- makeCluster(n_cores)
# Fork : on distribue chaque vecteur √† un c≈ìur
results <- parLapply(cl, vec_list, function(v) sum(v))
# Join : on additionne les sommes partielles
total_sum <- Reduce("+", results)
stopCluster(cl)
total_sum
library(parallel)
# Tri fusion parall√®le en fran√ßais
tri_fusion_parallele <- function(liste) {
n <- length(liste)
if (n <= 1) return(liste)    # Base : liste d‚Äôun seul √©l√©ment
milieu <- floor(n / 2)
# Cr√©er un cluster de 2 c≈ìurs pour trier les moiti√©s en parall√®le
cl <- makeCluster(2)
clusterExport(cl, varlist = c("tri_fusion_parallele"))
# Diviser et lancer r√©cursion en parall√®le (fork)
moities <- parLapply(cl, list(
liste[1:milieu],
liste[(milieu + 1):n]
), tri_fusion_parallele)
stopCluster(cl)
gauche <- moities[[1]]
droite <- moities[[2]]
# Combiner (fusionner deux listes tri√©es)
i <- j <- 1
resultat <- integer(0)
while (i <= length(gauche) && j <= length(droite)) {
if (gauche[i] <= droite[j]) {
resultat <- c(resultat, gauche[i]); i <- i + 1
} else {
resultat <- c(resultat, droite[j]); j <- j + 1
}
}
c(resultat, gauche[i:length(gauche)], droite[j:length(droite)])
}
# Exemple d‚Äôutilisation
set.seed(123)
ma_liste <- sample(1:100, 20, replace = TRUE)
cat("Liste non tri√©e :", ma_liste, "\n\n")
liste_triee <- tri_fusion_parallele(ma_liste)
library(parallel)
# Tri fusion parall√®le en fran√ßais
tri_fusion_parallele <- function(liste) {
n <- length(liste)
if (n <= 1) return(liste)
milieu <- floor(n / 2)
cl <- makeCluster(2)
# Charger le package et exporter la fonction dans chaque n≈ìud
clusterEvalQ(cl, library(parallel))  # <<-- ligne ajout√©e ici
clusterExport(cl, varlist = c("tri_fusion_parallele"))
# Appel r√©cursif parall√®le
moities <- parLapply(cl, list(
liste[1:milieu],
liste[(milieu + 1):n]
), tri_fusion_parallele)
stopCluster(cl)
gauche <- moities[[1]]
droite <- moities[[2]]
# Fusion des deux listes tri√©es
i <- j <- 1
resultat <- integer(0)
while (i <= length(gauche) && j <= length(droite)) {
if (gauche[i] <= droite[j]) {
resultat <- c(resultat, gauche[i]); i <- i + 1
} else {
resultat <- c(resultat, droite[j]); j <- j + 1
}
}
c(resultat, gauche[i:length(gauche)], droite[j:length(droite)])
}
# Exemple
set.seed(123)
ma_liste <- sample(1:100, 20, replace = TRUE)
cat("Liste non tri√©e :", ma_liste, "\n\n")
liste_triee <- tri_fusion_parallele(ma_liste)
library(parallel)
# Tri fusion parall√®le en fran√ßais
tri_fusion_parallele <- function(liste) {
n <- length(liste)
if (n <= 1) return(liste)
milieu <- floor(n / 2)
cl <- makeCluster(2)
# Charger le package et exporter la fonction dans chaque n≈ìud
clusterEvalQ(cl, library(parallel))  # <<-- ligne ajout√©e ici
clusterExport(cl, varlist = c("tri_fusion_parallele"))
# Appel r√©cursif parall√®le
moities <- parLapply(cl, list(
liste[1:milieu],
liste[(milieu + 1):n]
), tri_fusion_parallele)
stopCluster(cl)
gauche <- moities[[1]]
droite <- moities[[2]]
# Fusion des deux listes tri√©es
i <- j <- 1
resultat <- integer(0)
while (i <= length(gauche) && j <= length(droite)) {
if (gauche[i] <= droite[j]) {
resultat <- c(resultat, gauche[i]); i <- i + 1
} else {
resultat <- c(resultat, droite[j]); j <- j + 1
}
}
c(resultat, gauche[i:length(gauche)], droite[j:length(droite)])
}
# Exemple
set.seed(123)
ma_liste <- sample(1:100, 20, replace = TRUE)
cat("Liste non tri√©e :", ma_liste, "\n\n")
liste_triee <- tri_fusion_parallele(ma_liste)
setwd("E:/ISEP 2/MON DOSSIER/APPRENTISSAGE DES VACANCES/ISEP3/ME _ SEMESTRE 2/PROJET STATISTIQUE SOUS R ET PYTHON/GITHUB EXPOSE/Calcul_parall-le_surR_T6")
# Texte √† analyser (exemple simple)
phrases <- c(
"Le chat mange le poisson",
"Le chien court apr√®s le chat",
"Le poisson nage dans l'eau"
)
# --- Phase MAP ---
map_function <- function(phrase) {
# D√©coupage de la phrase en mots (cl√©s)
mots <- unlist(strsplit(tolower(phrase), "\\W+"))  # Ignorer la casse et la ponctuation
# G√©n√©ration des couples (mot, 1)
return(data.frame(mot = mots, valeur = 1))
}
# --- Phase REDUCE ---
reduce_function <- function(cles, valeurs) {
# Agr√©gation : somme des valeurs par cl√©
aggregate(valeur ~ mot, data = data.frame(mot = cles, valeur = valeurs), sum)
}
# Configuration du cluster (4 c≈ìurs)
cl <- makeCluster(4)
clusterExport(cl, c("map_function", "reduce_function"))
# --- MAP ---
# Appliquer la fonction map √† chaque phrase en parall√®le
resultats_map <- parLapply(cl, phrases, map_function)
# --- SHUFFLE (Regroupement des cl√©s) ---
# Combiner tous les r√©sultats partiels
donnees <- do.call(rbind, resultats_map)
# --- REDUCE ---
# Appliquer la fonction reduce sur les donn√©es group√©es
resultat_final <- reduce_function(donnees$mot, donnees$valeur)
# Arr√™t du cluster
stopCluster(cl)
print(resultat_final)
# Texte √† analyser (exemple simple)
phrases <- c(
"Le chat mange le poisson",
"Le chien court apr√®s le chat",
"Le poisson nage dans l'eau"
)
# --- Phase MAP ---
map_function <- function(phrase) {
# D√©coupage de la phrase en mots (cl√©s)
mots <- unlist(strsplit(tolower(phrase), "\\W+"))  # Ignorer la casse et la ponctuation
# G√©n√©ration des couples (mot, 1)
return(data.frame(mot = mots, valeur = 1))
}
# --- Phase REDUCE ---
reduce_function <- function(cles, valeurs) {
# Agr√©gation : somme des valeurs par cl√©
aggregate(valeur ~ mot, data = data.frame(mot = cles, valeur = valeurs), sum)
}
# Configuration du cluster (4 c≈ìurs)
cl <- makeCluster(4)
clusterExport(cl, c("map_function", "reduce_function"))
# --- MAP ---
# Appliquer la fonction map √† chaque phrase en parall√®le
resultats_map <- parLapply(cl, phrases, map_function)
# --- SHUFFLE (Regroupement des cl√©s) ---
# Combiner tous les r√©sultats partiels
donnees <- do.call(rbind, resultats_map)
# --- REDUCE ---
# Appliquer la fonction reduce sur les donn√©es group√©es
resultat_final <- reduce_function(donnees$mot, donnees$valeur)
# Arr√™t du cluster
stopCluster(cl)
print(resultat_final)
# Ce package n'a pas besoin d'√™tre t√©l√©charg√© au pr√©alable,
# il est directement disponible lorsque R est install√©
library(parallel)
# Nombre de coeurs physiques
nb_coeurs_physiques <- detectCores(logical = FALSE)
print(nb_coeurs_physiques)
ships <- read_csv("../data/ships.csv")
# 1. Pr√©paration des donn√©es
donnees_filtrees <- ships %>%
filter(!is.na(SPEED), SPEED > 0, !is.na(ship_type))
types_navires <- unique(donnees_filtrees$ship_type)
# Fonction de calcul de la moyenne pour un type de navire
calculer_moyenne <- function(type) {
donnees_filtrees %>%
filter(ship_type == type) %>%
summarise(type_navire = type,
vitesse_moyenne = mean(SPEED, na.rm = TRUE))
}
# 2. Fonction de calcul parall√®le avec 8 workers
parallele <- function() {
# Cr√©er le cluster avec 8 workers
cl <- makeCluster(8)
# Exporter les objets n√©cessaires aux workers
clusterExport(cl, varlist = c("donnees_filtrees", "types_navires", "calculer_moyenne"), envir = globalenv())
# Charger dplyr dans chaque worker
clusterEvalQ(cl, library(dplyr))
# Mesurer le temps de calcul
temps_calc <- system.time({
res <- parLapply(cl, types_navires, calculer_moyenne)
})[3]
# Arr√™ter le cluster
stopCluster(cl)
# Agr√©ger les r√©sultats
resultat_final <- bind_rows(res)
return(list(resultats = resultat_final, temps = temps_calc))
}
# 3. Appel de la fonction et affichage des r√©sultats
resultats <- parallele()
cat("Temps de calcul avec 12 workers :", resultats$temps, "secondes\n")
# √âtape 1 : Pr√©paration des donn√©es
donnees_filtrees <- ships %>%
filter(!is.na(SPEED), SPEED > 0, !is.na(ship_type))
# √âtape 2 : D√©finition des t√¢ches h√©t√©rog√®nes (chaque t√¢che est une fonction diff√©rente)
tache_moyennes <- function(data) {
data %>%
group_by(ship_type) %>%
summarise(vitesse_moyenne = mean(SPEED, na.rm = TRUE))
}
tache_regression <- function(data) {
lm(SPEED ~ LENGTH, data = data)  # Mod√®le lin√©aire
}
tache_statistiques <- function(data) {
data %>%
group_by(ship_type) %>%
summarise(
mediane = median(SPEED, na.rm = TRUE),
ecart_type = sd(SPEED, na.rm = TRUE)
)
}
# √âtape 3 : Configuration du cluster pour 3 workers (un par t√¢che)
cl <- makeCluster(3)
# Exportation des donn√©es et packages vers chaque worker (une seule fois)
clusterExport(cl, c("donnees_filtrees", "tache_moyennes", "tache_regression", "tache_statistiques"))
clusterEvalQ(cl, library(dplyr))
# √âtape 4 : Attribution des t√¢ches aux workers avec chronom√©trage (tictoc)
tic("Ex√©cution des t√¢ches en parall√®le")  # D√©marrer le chronom√®tre global
resultats <- parLapply(cl, list(tache_moyennes, tache_regression, tache_statistiques), function(f) {
f(donnees_filtrees)  # Chaque worker ex√©cute une fonction diff√©rente
})
toc()
# √âtape 5 : Arr√™t du cluster et extraction des r√©sultats
stopCluster(cl)
# Extraire les r√©sultats
resultats_moyennes <- resultats[[1]]  # Vitesses moyennes
resultats_regression <- resultats[[2]]    # Objet de r√©gression
resultats_stats <- resultats[[3]]     # Statistiques
# Affichage des r√©sultats
cat("R√©sultats des vitesses moyennes :\n")
print(resultats_moyennes)
cat("R√©sum√© du mod√®le de r√©gression :\n")
summary(resultats_regression)
cat("Statistiques :\n")
print(resultats_stats)
# √âtape 1 : Pr√©paration des donn√©es
donnees_filtrees <- ships %>%
filter(!is.na(SPEED), SPEED > 0, !is.na(ship_type))
# √âtape 2 : D√©finition des t√¢ches h√©t√©rog√®nes (chaque t√¢che est une fonction diff√©rente)
tache_moyennes <- function(data) {
data %>%
group_by(ship_type) %>%
summarise(vitesse_moyenne = mean(SPEED, na.rm = TRUE))
}
tache_regression <- function(data) {
lm(SPEED ~ LENGTH, data = data)  # Mod√®le lin√©aire
}
tache_statistiques <- function(data) {
data %>%
group_by(ship_type) %>%
summarise(
mediane = median(SPEED, na.rm = TRUE),
ecart_type = sd(SPEED, na.rm = TRUE)
)
}
# √âtape 3 : Configuration du cluster pour 3 workers (un par t√¢che)
cl <- makeCluster(3)
# Exportation des donn√©es et packages vers chaque worker (une seule fois)
clusterExport(cl, c("donnees_filtrees", "tache_moyennes", "tache_regression", "tache_statistiques"))
clusterEvalQ(cl, library(dplyr))
# √âtape 4 : Attribution des t√¢ches aux workers avec chronom√©trage (tictoc)
tic("Ex√©cution des t√¢ches en parall√®le")  # D√©marrer le chronom√®tre global
resultats <- parLapply(cl, list(tache_moyennes, tache_regression, tache_statistiques), function(f) {
f(donnees_filtrees)  # Chaque worker ex√©cute une fonction diff√©rente
})
toc()
# √âtape 5 : Arr√™t du cluster et extraction des r√©sultats
stopCluster(cl)
# Extraire les r√©sultats
resultats_moyennes <- resultats[[1]]  # Vitesses moyennes
resultats_regression <- resultats[[2]]    # Objet de r√©gression
resultats_stats <- resultats[[3]]     # Statistiques
# Fusionner les r√©sultats dans un seul tableau
tableau_resultats <- resultats_moyennes %>%
left_join(resultats_stats, by = "ship_type") %>%
mutate(coef_intercept = resultats_regression[1],  # Ajouter le coefficient d'interception de la r√©gression
coef_slope = resultats_regression[2])  # Ajouter le coefficient de pente de la r√©gression
# Affichage du tableau final
cat("Tableau r√©capitulatif des r√©sultats :\n")
print(tableau_resultats)
library(doParallel)
registerDoParallel(4)  # Utiliser 4 workers
resultats <- foreach(i = 1:5) %dopar% {
sqrt(i)  # Calcul de la racine carr√©e de chaque i
}
stopImplicitCluster()
library(doParallel)
registerDoParallel(4)  # Utiliser 4 workers
resultats <- foreach(i = 1:5) %dopar% {
sqrt(i)  # Calcul de la racine carr√©e de chaque i
}
stopImplicitCluster()
print(resultats)
library(foreach)
library(doParallel)
library(tictoc)
# Enregistrer 4 workers (coeurs)
registerDoParallel(4)
# üí° Test 1 : version s√©quentielle (pas en parall√®le)
tic("S√©quentiel")
result_sequentiel <- foreach(i = 1:5) %do% {
Sys.sleep(1)  # Simule un calcul de 1 seconde
i^2           # Exemple : carr√© de i
}
toc()
# üí° Test 2 : version parall√®le
tic("Parall√®le")
result_parallele <- foreach(i = 1:5) %dopar% {
Sys.sleep(1)  # M√™me t√¢che de 1 seconde
i^2
}
toc()
# Arr√™ter les workers
stopImplicitCluster()
# Affichage des r√©sultats
print(result_sequentiel)
print(result_parallele)
library(foreach)
library(doParallel)
library(tictoc)
# Enregistrer 4 workers (coeurs)
registerDoParallel(4)
# üí° Test 1 : version s√©quentielle (pas en parall√®le)
tic("S√©quentiel")
result_sequentiel <- foreach(i = 1:5) %do% {
i^2           #
}
toc()
# üí° Test 2 : version parall√®le
tic("Parall√®le")
result_parallele <- foreach(i = 1:5) %dopar% {
i^2
}
toc()
# Arr√™ter les workers
stopImplicitCluster()
# Affichage des r√©sultats
print(result_sequentiel)
print(result_parallele)
library(foreach)
library(doParallel)
library(tictoc)
# Enregistrer 4 workers (coeurs)
registerDoParallel(8)
# üí° Test 1 : version s√©quentielle (pas en parall√®le)
tic("S√©quentiel")
result_sequentiel <- foreach(i = 1:5) %do% {
i^2           #
}
toc()
# üí° Test 2 : version parall√®le
tic("Parall√®le")
result_parallele <- foreach(i = 1:5) %dopar% {
i^2
}
toc()
# Arr√™ter les workers
stopImplicitCluster()
# Affichage des r√©sultats
print(result_sequentiel)
print(result_parallele)
library(foreach)
library(doParallel)
library(tictoc)
# Enregistrer 4 workers (coeurs)
registerDoParallel(5)
# üí° Test 1 : version s√©quentielle (pas en parall√®le)
tic("S√©quentiel")
result_sequentiel <- foreach(i = 1:5) %do% {
i^2           #
}
toc()
# üí° Test 2 : version parall√®le
tic("Parall√®le")
result_parallele <- foreach(i = 1:5) %dopar% {
i^2
}
toc()
# Arr√™ter les workers
stopImplicitCluster()
# Affichage des r√©sultats
print(result_sequentiel)
print(result_parallele)
library(doParallel)
registerDoParallel(4)  # Utiliser 4 workers
resultats <- foreach(i = 1:5) %dopar% {
sqrt(i)  # Calcul de la racine carr√©e de chaque i
}
stopImplicitCluster()
print(resultats)
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
result <- foreach(i = 1:100) %dopar% sqrt(i)
stopCluster(cl)
print(resultats)
ships <- read_csv("../data/ships.csv")
# 1. Pr√©paration des donn√©es
donnees_filtrees <- ships %>%
filter(!is.na(SPEED), SPEED > 0, !is.na(ship_type))
types_navires <- unique(donnees_filtrees$ship_type)
# Fonction de calcul de la moyenne pour un type de navire
calculer_moyenne <- function(type) {
donnees_filtrees %>%
filter(ship_type == type) %>%
summarise(type_navire = type,
vitesse_moyenne = mean(SPEED, na.rm = TRUE))
}
# 2. Fonction de calcul parall√®le avec 8 workers
parallele <- function() {
# Cr√©er le cluster avec 8 workers
cl <- makeCluster(8)
# Exporter les objets n√©cessaires aux workers
clusterExport(cl, varlist = c("donnees_filtrees", "types_navires", "calculer_moyenne"), envir = globalenv())
# Charger dplyr dans chaque worker
clusterEvalQ(cl, library(dplyr))
# Mesurer le temps de calcul
temps_calc <- system.time({
res <- parLapply(cl, types_navires, calculer_moyenne)
})[3]
# Arr√™ter le cluster
stopCluster(cl)
# Agr√©ger les r√©sultats
resultat_final <- bind_rows(res)
return(list(resultats = resultat_final, temps = temps_calc))
}
# 3. Appel de la fonction et affichage des r√©sultats
resultats <- parallele()
cat("Temps de calcul avec 8 workers :", resultats$temps, "secondes\n")
# √âtape 1 : Pr√©paration des donn√©es
donnees_filtrees <- ships %>%
filter(!is.na(SPEED), SPEED > 0, !is.na(ship_type))
# √âtape 2 : D√©finition des t√¢ches h√©t√©rog√®nes (chaque t√¢che est une fonction diff√©rente)
tache_moyennes <- function(data) {
data %>%
group_by(ship_type) %>%
summarise(vitesse_moyenne = mean(SPEED, na.rm = TRUE))
}
tache_regression <- function(data) {
lm(SPEED ~ LENGTH, data = data)  # Mod√®le lin√©aire
}
tache_statistiques <- function(data) {
data %>%
group_by(ship_type) %>%
summarise(
mediane = median(SPEED, na.rm = TRUE),
ecart_type = sd(SPEED, na.rm = TRUE)
)
}
# √âtape 3 : Configuration du cluster pour 3 workers (un par t√¢che)
cl <- makeCluster(3)
# Exportation des donn√©es et packages vers chaque worker (une seule fois)
clusterExport(cl, c("donnees_filtrees", "tache_moyennes", "tache_regression", "tache_statistiques"))
clusterEvalQ(cl, library(dplyr))
# √âtape 4 : Attribution des t√¢ches aux workers avec chronom√©trage (tictoc)
tic("Ex√©cution des t√¢ches en parall√®le")  # D√©marrer le chronom√®tre global
resultats <- parLapply(cl, list(tache_moyennes, tache_regression, tache_statistiques), function(f) {
f(donnees_filtrees)  # Chaque worker ex√©cute une fonction diff√©rente
})
toc()
# √âtape 5 : Arr√™t du cluster et extraction des r√©sultats
stopCluster(cl)
# Extraire les r√©sultats
resultats_moyennes <- resultats[[1]]  # Vitesses moyennes
resultats_regression <- resultats[[2]]    # Objet de r√©gression
resultats_stats <- resultats[[3]]     # Statistiques
# Fusionner les r√©sultats dans un seul tableau
tableau_resultats <- resultats_moyennes %>%
left_join(resultats_stats, by = "ship_type") %>%
mutate(coef_intercept = resultats_regression[1],  # Ajouter le coefficient d'interception de la r√©gression
coef_slope = resultats_regression[2])  # Ajouter le coefficient de pente de la r√©gression
# Affichage du tableau final
cat("Tableau r√©capitulatif des r√©sultats :\n")
print(tableau_resultats)
