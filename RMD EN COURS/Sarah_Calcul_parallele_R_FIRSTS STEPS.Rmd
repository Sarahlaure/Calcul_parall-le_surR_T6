---
title: "Calcul parallele sur R"
author: "Fogwoung Djoufack Sarah-Laure & Aissatou Sega Diallo"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
fontsize: 12pt  
---

# INTRODUCTION

## Contexte et motivations ayant donné lieu au calcul parallele

L’ère du Big Data, marquée par l’explosion des réseaux sociaux, de l’IoT (Internet des Objets), et des simulations numériques, a entraîné une croissance vertigineuse des données. Selon IBM, 90 % des données mondiales ont été générées au cours des deux dernières années seulement – un rythme qui s’accélère avec plus de 2,5 trillions d’octets créés quotidiennement (https://bernardmarr.com/how-much-data-do-we-create-every-day-the-mind-blowing-stats-everyone-should-read/.

Les applications critiques comme l’analyse financière en temps réel, l’entraînement de modèles de Deep Learning (ex : GPT-4 avec 1,7 trillion de paramètres), ou les prévisions météorologiques à haute résolution, exigent désormais des traitements en millisecondes. Or, un processeur monocœur classique ne peut traiter qu’environ 3 milliards d’instructions par seconde (3 GHz), rendant le calcul séquentiel totalement inadapté à ces défis.

### Loi de Moore et plafonnement des fréquences CPU 

La loi de Moore, énoncée en 1965, dit simplement que chaque nouvelle génération de puces électroniques peut contenir environ deux fois plus de transistors que la précédente, et ce tous les deux ans. Les transistors sont ces petits interrupteurs qui composent le processeur: plus on en place sur une puce, plus on peut y faire de calculs en même temps. Grâce à cette croissance régulière, on est passé de quelques milliers de transistors dans les premiers microprocesseurs à plusieurs dizaines de milliards aujourd’hui, ce qui a permis d’ajouter des fonctions (mémoire cache, unités de calcul spécialisées…) sans changer la façon dont chaque transistor fonctionne.

Cependant, on ne peut pas continuer à augmenter indéfiniment la «vitesse» d’un seul transistor, c’est‑à‑dire la fréquence d’horloge, car au‑delà d’environ 4 GHz la puce chauffe trop et consomme trop d’énergie. Pour continuer à gagner en performance, les fabricants ont donc multiplié le nombre de cœurs sur une même puce (on parle de multi‑core) et ajouté des circuits spécialisés (GPU pour les graphismes, TPU pour l’intelligence artificielle, etc.). Ces solutions permettent de répartir les calculs sur plusieurs unités en parallèle, sans faire monter la température au point de devoir arrêter la machine.
 
## Qu'est-ce que le calcul parallèle ?

Le **calcul parallèle** consiste à exécuter plusieurs tâches en même temps en utilisant plusieurs ressources informatiques(appelées coeurs ou threads que nous définirons plus bas). En pratique, au lieu de réaliser toutes les opérations une par une (calcul séquentiel), on les répartit entre plusieurs processeurs ou coeurs pour exécuter plusieurs tâches en même temps.

Dans un calcul parallèle, un grand problème est **divisé** en plusieurs sous-problèmes plus petits, et ces sous-problèmes sont **résolus simultanément**, ce qui permet de gagner du temps.

## Différence entre calcul séquentiel et calcul parallèle

### Calcul Séquentiel

**Principe :**  
Chaque tâche est exécutée l'une après l'autre.  
*Exemple :*  
Si vous devez traiter 100 itérations d'un calcul sur une grande base de données, chaque itération attend la fin de la précédente.

**Avantages :**  
- Simplicité d'implémentation.  
- Gestion de la mémoire souvent plus directe.

**Limitations :**  
- Lorsque le volume de données est important, le temps d'exécution peut devenir long. 


### Calcul Parallèle

**Principe :**  
Le travail est divisé entre plusieurs cœurs du processeur, permettant l'exécution simultanée des tâches.  
*Exemple :*  
Si votre ordinateur dispose de 4 coeurs, vous pouvez distribuer les 100 itérations en affectant environ 25 itérations à chaque coeur pour qu'elles s'exécutent simultanément.

**Avantages :**  
- Réduction significative du temps de calcul grâce à l'exécution simultanée des tâches.

**Limitations :**  
- La mise en place du parallélisme demande une gestion de la répartition des tâches et la collecte des résultats, ce qui est généralement pris en charge par le "programme maître".

## Différence entre concurrence et parallélisme

La **concurrence** (concurrent computing) désigne la capacité d’un système à gérer plusieurs tâches en même temps, sans forcément les exécuter physiquement simultanément. 
Concrètement, un seul cœur de processeur peut passer très rapidement d’une tâche à l’autre (entrelacement ou time‑sharing), donnant l’illusion d’un traitement parallèle alors qu’à chaque instant, une seule tâche est réellement active. L'objectif principal ici est d'améliorer la réactivité et la gestion des ressources (ne pas bloquer l’ensemble du système lorsqu’une tâche attend une opération d’entrée/sortie).
Alors que, comme on l'a dit precédemment, le parallélisme correspond à l’exécution physique et simultanée de plusieurs tâches sur plusieurs unités de calcul (cœurs CPU, processeurs, GPU…). Ainsi chaque cœur traite sa propre tâche indépendamment et en même temps que les autres, et donc l'objectif ici est de réduire drastiquement le temps total d’exécution pour les calculs lourds.

## Concepts Techniques

### 1. Coeurs du Processeur

## DEFINIR PROCESSEIR ET DONNER UN APERCU AVEC LES COEURS ET THREAD SI POSSIBLE
**Définition :**  
Un **cœur** (ou core) est une unité de calcul indépendante au sein d’un même processeur. Chaque cœur dispose de son propre jeu de registres, d’une unité arithmétique/logique et d’un cache. Plus un processeur compte de cœurs, plus il peut traiter de tâches vraiment en parallèle. 

- **Exemple :**  
  Un processeur *quad-core* possède 4 coeurs physiques, chacun pouvant exécuter des instructions indépendamment des autres.

- Par ailleurs, il ne faut pas se fier aux noms marketing: un Intel Core i5 n’a pas nécessairement 5 coeurs ! Par exemple, un i5-10400 possède 6 coeurs physiques. Les nombres dans les noms (i3, i5, i7) reflètent une gamme de performance, pas le nombre de coeurs.

- Pour connaître le nombre de coeurs disponibles sur votre machine, vous pouvez utiliser la fonction `detectCores()` du package **parallel**, avec l'option FALSE sur logical. 

```{r coeurs }
# Ce package n'a pas besoin d'être téléchargé au préalable,
# il est directement disponible lorsque R est installé 
library(parallel) 

# Nombre de coeurs physiques
nb_coeurs_physiques <- detectCores(logical = FALSE)
print(nb_coeurs_physiques)
``` 

Dans mon cas par exemple, mon core i5 a 10 coeurs.


### 2. Threads (ou Processeurs Logiques)

- **Définition :**  
Un **thread** est la plus petite unité d’exécution gérée par le système d’exploitation: c’est une séquence d’instructions qu’un cœur peut traiter.

Chaque thread possède son propre contexte (ensemble des informations que le CPU doit sauvegarder et restaurer pour reprendre l’exécution exactement là où il s’était arrêté), mais partage avec les autres threads du même cœur les ressources matérielles (unités arithmétiques, caches).

- Pour connaître le nombre de threads disponibles sur votre machine, vous pouvez utiliser la même fonction `detectCores()` du package **parallel**, avec l'option TRUE sur logical. 

```{r threads}
# Nombre de threads (unités logiques)
nb_threads <- detectCores(logical = TRUE)
print(nb_threads)

``` 

### 3.**Hyper-threading :**  
  C'est une technologie qui permet à un seul cœur physique de se présenter au système d'exploitation comme deux (et quelque fois plus de 2) cœurs logiques (threads) simultanés.  
  
  - **Exemple :**  
    Un processeur quad-core sans hyper-threading gère 4 threads mais lorsqu'il est  doté d'hyper-threading, il peut gérer 8 threads. De manière generale le système d'exploitation considere donc que l'ordinateur a 8 coeurs puisqu'il peut théoriquement exécuter 8 tâches en même temps, mais en réalité, c'est rien que 4 coeurs physiques qui existent réellement. 

Toutefois,  l’hyper-threading améliore l’efficacité, pas la puissance brute d'un coeur. 
### Lien entre Coeurs et Threads et calcul parallele

- **Physiquement :**  
  Vous disposez d'un nombre fixe de coeurs physiques (par exemple, 4 coeurs sur un processeur quad-core).
  
- **Logiquement :**  
  Chaque coeur peut être "dédoublé" en plusieurs threads grâce à l'hyper-threading. Ainsi, même avec 4 coeurs, vous pouvez avoir plus d'unités d'exécution simultanée (par exemple, 8 threads).

- **En pratique pour le calcul parallèle :**  
  On parle souvent de "coeurs" pour simplifier, mais ce sont en réalité les **threads** (unités logiques) qui exécutent les tâches. Le nombre de threads disponibles détermine combien de tâches peuvent être réellement exécutées en parallèle.

Par exemple, dans mon cas, mon ordinateur a 10 coeurs et 12 threads et donc il y a 2 coeurs qui grace au hyper-threading gerent 2 threads chacun et les 8 autres coeurs gerent 1 thread chacun. Donc pour le calcul parallele, R va utiliser le nombre de threads=12 pour optimiser le calcul parallèle



### 4. Programme Maître et son rôle dans le calcul parallèle

Le programme maître est essentiel pour coordonner le calcul parallèle en distribuant les tâches et en recueillant les résultats. Il est chargé de trois responsabilités principales :

1. **Initialisation des workers**  

   - Création des workers et chargement des packages nécessaires. 
   
   - **Coût d’initialisation** : cette étape peut prendre plusieurs secondes, car chaque worker doit démarrer et recevoir les outils nécessaires.  
    
     - **Amortissement de l'overhead** : pour que le parallélisme soit rentable, chaque worker doit avoir **suffisamment de travail** pour compenser ce temps de démarrage, dans le cas contraire, le calcul séquentiel peut etre preferable. 
     
    - *Exemple*: Si le démarrage d’un worker prend 100 ms et que sa tâche dure 10 ms, le coût d’overhead est prohibitif. 
( L’**overhead** ou **surcharge** regroupe toutes les opérations **hors calcul** qui consomment du temps:
- Création et destruction des workers  
- Exportation des données et des fonctions  
- Chargement des packages  
- Communication entre le maître et les workers  
Ces coûts doivent être **compensés** par la durée des calculs parallèles pour que l’approche soit bénéfique.)

2. **Répartition des tâches:**  

Le programme maître divise une tâche globale en plusieurs sous-tâches qui peuvent être exécutées simultanément par différents threads ou cœurs de processeur. L'objectif est de distribuer la charge de travail pour maximiser l'efficacité de l'exécution parallèle.
Ainsi, chaque thread travaille sur une portion de la tâche, ce qui accélère l'exécution du programme.

3. **Lancement en parallèle:**  

Une fois que les sous-tâches sont réparties, le programme maître envoie chaque sous-tâche aux threads disponibles pour exécution simultanée. Ces threads peuvent être répartis sur les différents cœurs de processeur ou machines.

- **Collecte et agrégation des résultats:**  
Après que chaque thread a terminé sa partie du travail, le programme maître récupère les résultats produits. Souvent, cela se fait à l'aide d'une fonction comme do.call() en R, qui permet de combiner ou de regrouper les résultats des différentes tâches en un seul ensemble de données final.

D'autres part, nous distinguons les sous-programmes (ou workers).

### 5. Cluster et worker 

Un **cluster** est l’ensemble des processus R (ou threads) que l’on lance pour exécuter un calcul en parallèle.  
- On crée un cluster avec `makeCluster(n)`, où `n` est le nombre de workers souhaités.  
- Le cluster sert à **répartir** le travail sur plusieurs unités de calcul (cœurs ou machines).

Un **worker** est un **processus individuel** du cluster :  
- Il reçoit **une sous‑tâche** du programme maître.  
- Il exécute la fonction assignée sur son lot de données.
- Il renvoie son résultat au programme maître pour agrégation.

D'autre part, on distingue le **cluster** est un ensemble de processus R (ou de threads) lancés pour exécuter des tâches en parallèle.  
- Chaque processus du cluster est appelé un **worker**.  
- Le cluster permet de répartir le travail sur plusieurs unités de calcul (cœurs ou machines).

**Remarque**  
- On peut créer plus de workers que de threads logiques.
- Dans ce cas, les workers excédentaires restent en **attente** jusqu’à ce qu’un thread se libère.  
- Il faut veiller à ce que chaque worker ait **suffisamment** de travail pour amortir le coût de démarrage du cluster. 


-- Mise en oeuvre avec R (structure globale)

Les fonctions proviennent du package parallele aussi. 

Etape 1: on initialise un cluster, c’est-à-dire un groupe de workers, en précisant combien on en veut (par exemple, dans notre cas, on definit autant que le nombre de threads disponibles: **cl <- makeCluster(nb_threads)**).

Etape 2: Puis la fonction parLapply() permet de distribuer les sous-tâches à chaque worker. On lui donne une liste tâches  et une fonction f à appliquer à chaque élément. (**résultats <- parLapply(cl, tâches, f)**). 

Etape 3: Arrêt du cluster (libération des ressources): Une fois toutes les tâches terminées, on arrête proprement les workers.Cela libère la mémoire et évite de laisser des processus inutilisés tourner en arrière-plan. On fait de ce fait: **stopCluster**. 

Etape 4: Chaque worker renvoie un résultat (souvent un tableau ou un vecteur).On utilise **do.call(rbind, ...)** pour assembler tous les résultats obtenus en un seul tableau cohérent, ligne par ligne.

Faisons un exemple et calculons la moyenne des vitesse moyenne pour chaque type de navire pour le fichier ships.csv.

Step 1: définissons les paramètres

```{r param}
library(readr)
library(dplyr)

# Importation de la base 
ships <- read_csv("data/ships.csv")  

# Filtrage pour retirer les vitesses manquantes ou nulles
donnees_filtrees <- ships %>%
  filter(!is.na(SPEED), SPEED > 0, !is.na(ship_type))

# Liste des types de navires à traiter
types_navires <- unique(donnees_filtrees$ship_type)
print(types_navires)

# Fonction à appliquer : moyenne de la vitesse pour un type donné
calculer_moyenne <- function(type) {
  donnees_filtrees %>%
    filter(ship_type == type) %>%
    summarise(vitesse_moyenne = mean(SPEED)) %>%
    mutate(type_navire = type)
}
```
Step 2: Méthode séquentielle

```{r sequentielle}
temps_sequentiel <- system.time({
  ## Appliquer la fonction à chaque type de navires
  resultat_sequentiel <- lapply(types_navires, calculer_moyenne)
  ## Rassembler les resultats et retourne une liste
  resultat_final_sequentiel <- bind_rows(resultat_sequentiel) 
})

print("Résultat séquentiel :")
print(resultat_final_sequentiel)
print(paste("Temps séquentiel :", round(temps_sequentiel[3], 2), "secondes"))
```

Step 3: Méthode parallele

Le programme maitre fait la preparation globale des données (chargement, filtre et identification des types uniques), puis initie le cluster (en definissant donc le nombre de workers qui seront au nombre de 10 ici) puis distribute les données à chaque worker.
Durant cette phase, chaque worker exécute séquentiellement calculer_moyenne() sur ses types assignés, sans interférence avec les autres. Cette isolation garantit l’absence de conflits de mémoire mais nécessite une duplication initiale des données.
Une fois tous les résultats partiels reçus, le maître utilise bind_rows() pour fusionner les dataframes individuels en un seul tableau. Enfin, stopCluster() termine proprement les workers, libérant les ressources système. 

```{r parallele , warning=FALSE, message=FALSE}

# 1. Préparation des données
donnees_filtrees <- ships %>%
  filter(!is.na(SPEED), SPEED > 0, !is.na(ship_type))

types_navires <- unique(donnees_filtrees$ship_type)

# Fonction de calcul de la moyenne pour un type de navire
calculer_moyenne <- function(type) {
  donnees_filtrees %>%
    filter(ship_type == type) %>%
    summarise(type_navire = type,
              vitesse_moyenne = mean(SPEED, na.rm = TRUE))
}

# 2. Fonction de calcul parallèle avec 8 workers
parallele <- function() {
  # Créer le cluster avec 8 workers
  cl <- makeCluster(8)

  # Exporter les objets nécessaires aux workers
  clusterExport(cl, varlist = c("donnees_filtrees", "types_navires", "calculer_moyenne"), envir = globalenv())

  # Charger dplyr dans chaque worker
  clusterEvalQ(cl, library(dplyr))

  # Mesurer le temps de calcul
  temps_calc <- system.time({
    res <- parLapply(cl, types_navires, calculer_moyenne)
  })[3]

  # Arrêter le cluster
  stopCluster(cl)

  # Agréger les résultats
  resultat_final <- bind_rows(res)

  return(list(resultats = resultat_final, temps = temps_calc))
}

# 3. Appel de la fonction et affichage des résultats
resultats <- parallele()
cat("Temps de calcul avec 12 workers :", resultats$temps, "secondes\n")

```

Et on remarque une diminution du temps d'execution lorsqu'on augmente le nombre de workers. 

Dans l'exemple précédent, nous avons appliqué la même opération (ici, calculer_moyenne()) à différents sous-ensembles de données, chaque worker traitant une partie distincte des données. Ce type de répartition correspond à ce qu’on appelle le parallélisme de données.

Cependant, dans d’autres situations, ce n’est pas la même tâche qu’on souhaite répartir, mais des opérations différentes à appliquer sur le même ensemble de données. Dans ce cas, on parle plutôt de parallélisme de tâches, où chaque worker exécute une fonction différente.

##	Les différents types de parallélisme 

Dans cette partie, nous explorons les types de parallélisme que l'on peut utiliser pour diviser une tâche complexe en plusieurs sous-tâches exécutées simultanément.

### Parallélisme des données vs paralléliste des taches 

#### Parallélisme de données

Le **parallélisme de données** consiste à prendre un même traitement et à l’appliquer **simultanément** à plusieurs **sous‑ensembles** d’un grand jeu de données.  
- **Principe** : on divise les données en morceaux indépendants (blocs de lignes, groupes de pays, plages horaires).  
- **Exécution** : chaque cœur (ou worker) reçoit un sous‑ensemble et réalise exactement la même opération (tri, somme, moyenne, etc.).  
- **Quand l’utiliser** :  
  - Traitement de **grandes bases de données** (Big Data)
  - Opérations répétitives et uniformes (ex. calcul de moyennes, transformations de colonnes)
  
- **Avantage** : excellente montée en charge dès que le volume de données est important, car chaque cœur peut travailler de son côté sans attendre les autres.

 **Exemple** : c'est ce qui a été ait précédemment en divisant les observations en plusieurs morceaux et calculé, pour chacun, la moyene des vitesse moyenne pour les différents types de train.

### Parallélisme de tâches

Le **parallélisme de tâches** consiste à exécuter **différentes opérations** en même temps, sur un même ou plusieurs jeux de données.  
- **Principe** : on définit plusieurs tâches **distinctes** (nettoyage, calcul de statistiques, visualisation, export), puis on les lance **en parallèle**.  
- **Exécution** : chaque worker prend en charge une tâche spécifique, sans interférer avec les autres.  
- **Quand l’utiliser** :  
  - Chaînes de traitement où chaque étape est indépendante  
  - Workflows complexes (prétraitement, analyse, génération de rapports)  
- **Avantage** : accélère l’exécution globale d’un pipeline en répartissant des opérations hétérogènes sur plusieurs ressources.

**Exemple*:
Une tâche fait le nettoyage des données, une autre effectue une analyse statistique, et une autre génère des graphiques. Ces trois tâches sont effectuées en parallèle.

**Application:** Exécuter en parallèle trois traitements différents sur les données de navires : 1 worker pour calculer la vitesse moyenne par type de navire, 1 navire pour effectuer une regression linéaire entre la vitesse et la longueur des navires, un autre qui génre un rapport statistique avec médiane et écart-type.

```{r parallelisme_taches , warning=FALSE, message=FALSE}

# Étape 1 : Préparation des données 
donnees_filtrees <- ships %>%
  filter(!is.na(SPEED), SPEED > 0, !is.na(ship_type))

# Étape 2 : Définition des tâches hétérogènes (chaque tâche est une fonction différente)
tache_moyennes <- function(data) {
  data %>%
    group_by(ship_type) %>%
    summarise(vitesse_moyenne = mean(SPEED, na.rm = TRUE))
}

tache_regression <- function(data) {
  lm(SPEED ~ LENGTH, data = data)  # Modèle linéaire
}

tache_statistiques <- function(data) {
  data %>%
    group_by(ship_type) %>%
    summarise(
      mediane = median(SPEED, na.rm = TRUE),
      ecart_type = sd(SPEED, na.rm = TRUE)
    )
}

# Étape 3 : Configuration du cluster pour 3 workers (un par tâche)
cl <- makeCluster(3)

# Exportation des données et packages vers chaque worker
clusterExport(cl, "donnees_filtrees")
clusterEvalQ(cl, library(dplyr))

# Étape 4 : Attribution des tâches aux workers
temps_debut <- Sys.time()
resultats <- clusterApply(cl, list(tache_moyennes, tache_regression, tache_statistiques), function(f) {
  f(donnees_filtrees)  # Chaque worker exécute une fonction différente
})
temps_fin <- Sys.time()

# Étape 5 : Arrêt du cluster et extraction des résultats
stopCluster(cl)

resultats_moyennes <- resultats[[1]]  # Vitesses moyennes
resultats_regression <- resultats[[2]]    # Objet de régression
resultats_stats <- resultats[[3]]     # Statistiques

# Affichage
cat("Temps total :", round(temps_fin - temps_debut, 2), "secondes\n")
print(resultats_moyennes)
summary(resultats_modele)  # Résumé de la régression
print(resultats_stats)
```

Pour le parallelisme de taches, il est généralement conseillé de **fixer le nombre de workers à plus égale nombre de cœurs physiques** de votre machine:

En effet, dans le cas où on a **Plus de workers que de cœurs**, même si l'hyper‑threading permet à un cœur de traiter plusieurs tâches simultanément, les threads d'un même cœur **partagent les mêmes ressources**.  
  Ainsi, lorsque plusieurs tâches lourdes sont exécutées en même temps et qu’un même cœur doit se les partager, il doit diviser ses ressources (comme le temps de calcul) entre elles. Cela crée une forme d’encombrement, ce qu’on appelle une congestion, qui ralentit l’exécution des tâches à cause de la compétition entre les workers pour accéder aux ressources, et de la surcharge liée à leur gestion.

En parallélisme de données, le nombre de workers doit être proche du nombre de cœurs physiques pour les calculs lourds. Si les tâches sont rapides, on peut augmenter les workers, mais de maniere prudente. 

## Parallélisme distribué et parallélisme partagé 

Il existe deux principales approches pour utiliser plusieurs processeurs afin de faire du calcul parallèle : le parallélisme distribué et le parallélisme partagé (ou calcul parallele en local). Ces approches déterminent comment les ressources sont partagées entre plusieurs processeurs, qu'ils soient dans un même ordinateur ou répartis sur plusieurs machines.

Dans ce modèle, **tous les workers accèdent à la même mémoire centrale**. Cela signifie qu'ils peuvent lire et écrire dans les mêmes objets R si on ne prend pas de précautions. 

Le *parallélisme partagé* est basé sur le fait que tous les workers accèdent à la même mémoire centrale RAM.
C'est le modèle utilisé **lorsqu'on travaille sur une seule machine**, équipée de plusieurs cœurs de processeur.

D'autre part, le *parallélisme distribué* va plus loin en répartissant le calcul sur plusieurs machines connectées par un réseau. Chaque machine travaille sur une portion des données et communique avec les autres machines pour échanger des informations ou combiner les résultats. Dans ce cas, chaque machine peut avoir sa propre mémoire et ses propres ressources, et elles doivent s'échanger des données via un réseau (comme Internet ou un réseau local).

Nous ferons deux applications pratiques pour expliciter ces deux méthodes. 

## Packages et fonctions de base du calcul parallele

### 1. Package **parallel**

Ce package fait partie de l’installation standard de R et est utilisé pour répartir des tâches entre les cœurs d’un même ordinateur (et donc dans un parallélisme partagé). 

- `makeCluster(n)` : crée un cluster de `n` workers.
- `clusterExport(cl, varlist)` : exporte les objets R nécessaires aux workers dans leurs environnements respectifs.
- `clusterEvaLQ(cl, expr): 	Exécute une commande dans tous les workers
- `parLapply(cl, X, FUN)` : version parallèle de `lapply. La base de données ou tout autre objet X est divisé en sous ensemble qui seront traité par un worker différent du cluster cl et chaque worker applique la fonction FUN a chaque élément à sa charge. Et à la fin les résultats sont présentés sous forme de liste. 
- `parSapply(cl, X, FUN)` : Meme principe que parLapply mais ici le résultat est simplifié et n'est pas forcément sous forme d'une liste. 
- `mclapply(X, FUN, mc.cores)` : version parallèle de `lapply` pour Unix/Linux/Mac (pas Windows).
- `stopCluster(cl)` : arrête proprement le cluster.


### 2. Package **snow** (Simple Network of Workstations)

Package plus flexible que parallel, surtout utile pour le parallélisme distribué, mais fonctionne aussi en local.En effet il est utilisé pour créer des clusters de machines (ou de workers sur une même machine) et répartir des tâches.
Il comporte les


## Importance du calcul parallèle

Dans le domaine de la science des données, de la statistique et même du machine learning , le calcul parallèle est essentiel car il permet de :

1. **Accélérer le traitement des données** : En divisant le travail, on le fait plus rapidement. Par exemple, pour calculer des moyennes ou d'autres statistiques sur une grande base de données, l'exécution en parallèle permet de distribuer le travail et de gagner du temps.

2. **Optimiser l’utilisation des ressources** : Plusieurs processeurs ou machines travaillent ensemble, ce qui permet de mieux exploiter la puissance de calcul disponible.
3. **Gérer les grandes quantités de données** : Pour des bases contenant des millions voire des dizaines de millions de lignes, le calcul séquentiel serait trop lent pour fournir des résultats en temps utile.

Pour mieux comprendre celà, nous allons generer un jeu de données contenant 20 000 lignes représentant des revenus dans différentes régions du Sénégal puis comparer les temps d'exécution des calculs réalisés en mode séquentiel et en mode parallèle.

- *Generons les données* 

On va simuler des données comprenant des identifiants (id), des sexes (Homme/Femme), des régions (par exemple, 5 régions au Sénégal), et des revenus qui suivent une distribution normale.

```{r alea, warning=FALSE}
set.seed(123)
library(dplyr)

# Création d'une base plus volumineuse (10 millions de lignes)
df <- data.frame(
  id = 1:1e7, # 10 fois plus de données
  sexe = sample(c("Homme", "Femme"), 1e7, replace = TRUE),
  region = sample(c("Dakar", "Thiès", "Saint-Louis", "Ziguinchor", "Kaolack"), 
                  1e7, replace = TRUE),
  revenu = rnorm(1e7, mean = 250000, sd = 50000)
)

```

- **Methode séquentielle**
Dans cette méthode, nous allons calculer la moyenne des revenus par région de manière séquentielle.

```{r }
system.time({
  result_seq <- df %>%
    group_by(region) %>%
    summarise(
      moyenne = mean(revenu),
      ecart_type = sd(revenu), # Ajout d'un calcul supplémentaire
      count = n()
    )
})

```

**En calcul parallèle**

Dans cette méthode, nous allons répartir le travail sur 12 threads disponibles pour exécuter la même opération en parallèle.
```{r }

########## INSTALLATION DES PACKAGES ##########
# Exécuter cette partie une seule fois
# install.packages(c("dplyr", "doParallel", "foreach", "ggplot2"))

#library(doParallel)
#library(foreach)

# Détection automatique des coeurs
#n_cores <- detectCores() - 1 # Garde un coeur libre
#cl <- makeCluster(n_cores)
#registerDoParallel(cl)

#system.time({
#  result_par <- foreach(
#    region_split = split(df, df$region), 
#    .combine = bind_rows,
#    .packages = "dplyr"
#  ) %dopar% {
 #   region_split %>%
#      summarise(
#        region = first(region),
#        moyenne = mean(revenu),
#        ecart_type = sd(revenu),
#        count = n()
#      )
#  }
#})

#stopCluster(cl)

# Probleme to be solve, ca semble prendre plus de temps bizzarement
```


# Outils et packages pour le calcul parallèle en R 

Dans cette section, nous allons explorer les outils et packages qui permettent de mettre en œuvre le calcul parallèle en R pour les deux grandes méthodes de parallélisation : parallélisation locale et parallélisation distribuée. 

## 1. Calcul Parallèle en Local (Sur un Seul Ordinateur)

### 1.1 Le Package `parallel`

- **Description :**  
  Le package `parallel` est intégré à R et fournit des fonctions de base pour la parallélisation, telles que :
  - `mclapply()`, `mcmapply()`: fonctionnent sous Linux/Mac pour lancer des tâches en parallèle.
  - `makeCluster()`, `clusterApply()`, `parLapply()`, etc. : ces fonctions permettent de créer un cluster de workers, c'est-à-dire d'ouvrir plusieurs sessions R en parallèle (fonctionne aussi sur Windows).
  
- **Exemple de Code :**
```{r }
  library(parallel)
  
  # Définir le nombre de cores à utiliser
  n_cores <- detectCores(logical = TRUE)  # par exemple, 12 sur ma machine
  
  # Exemple avec mclapply (fonctionne sur Linux/Mac)
#  resultats <- mclapply(1:10, function(x) { sum(rnorm(1e6)) }, mc.cores = n_cores)
#  print(resultats)
 
  # Exemple avec clusterApply
  
# Créer un cluster de 4 workers pour exécuter des tâches en parallèle
cl <- makeCluster(4)

# Appliquer une fonction à chaque élément du vecteur 1:10 
# en répartissant les tâches sur les 4 workers.
# Pour chaque élément (de 1 à 10), la fonction 
# génère 1 million de nombres aléatoires (rnorm(1e6))
# et calcule leur somme (sum(rnorm(1e6))).
resultats2 <- clusterApply(cl, 1:10, function(x) { sum(rnorm(1e6)) })

# Libérer le cluster en fermant les 4 workers, 
# afin de libérer les ressources système utilisées
stopCluster(cl)

# Afficher la liste des 10 résultats obtenus, 
# chaque élément correspondant à la somme calculée par la fonction
print(resultats2)
```

JUST FOR ME: Je me posais la question de pourquoi là j'ai 12 threads dans mon ordi et là je suis entrain de traiter 10 vecteurs d'éleme,ts alors pourquoi ne pas utiliser 10threads alors que j'en ai la possibilité. Mais enfaite, certe là en utilisant 10threads et donc 10workers, ca reduirait le temps de traitement mais parfois askip c'est mieux de choisir un nombre plus faible pour éviter de saturer le systeme ou pour des raisons de gestion de la mémoire.  

MAIS COMPARONS LE TEMPS POUR VOIR 

```{r }
library(parallel)

# Comparaison avec 4 workers (threads)
cl4 <- makeCluster(4)  # Créer un cluster avec 4 workers
time_4 <- system.time({
  # Appliquer la fonction à chaque élément de 1:10 sur le cluster de 4 workers
  result_4 <- clusterApply(cl4, 1:10, function(x) { sum(rnorm(1e6)) })
})
stopCluster(cl4)  # Libérer le cluster
print("Temps avec 4 workers :")
print(time_4)

# Comparaison avec 10 workers (threads)
cl10 <- makeCluster(10)  # Créer un cluster avec 10 workers
time_10 <- system.time({
  # Appliquer la fonction à chaque élément de 1:10 sur le cluster de 10 workers
  result_10 <- clusterApply(cl10, 1:10, function(x) { sum(rnorm(1e6)) })
})
stopCluster(cl10)  # Libérer le cluster
print("Temps avec 10 workers :")
print(time_10)
```


On voit que le temps avec 4 workers est de 0,16 secondes et le temps avec les 10 workers est de 0,08 workers. Mais quand on ouvre le gestionnaire de taches pour voir la mémoire utilisée par chacune et qu'on somme l'espace mémmoir utilisée par les 4 workers d'une part et puis l'espace memoir pour les 10 workers on voit bien cette diffrence de taille de memoire utilisée. (Aussi pour voir cet espace memoire utilisé,on lance le programme puis on peut aller dans le gestionnaire de taches puis aller sur details puis rechercher R script exe qui montre l'espace memoire utilisé pour chacun des workers lancés)

BONNE APPLICATION DE PARALLELISME 
```{r param}
myfun <- function(r, mean = 0, sd = 1) {
mean(rnorm(r, mean = mean, sd = sd))
}
r_values <- rep(c(10, 1000, 100000, 10000000), each = 25)
resultats <- data.frame(r_values = factor(r_values))
time_sapply <- system.time(
resultats$res_non_par <- sapply(r_values, FUN = myfun,
mean = 5, sd = 10) # options de la fonction myfun
)
time_sapply
```
```{r param}
P <- 4 # définir le nombre de coeurs
cl <- makeCluster(P) # réserve 4 coeurs - début du calcul
time_par <- system.time(
res_par <- clusterApply(cl, r_values, fun = myfun, # évalue myfun sur r_values
mean = 5, sd = 10) # options de myfun
)
stopCluster(cl) # libère 4 coeurs - fin du calcul
time_par

```


PENSER MAYBE A METTRE UNE CAPTURE D'ECRAN POUR LA COMPARAISON

LA SUITE SUR LES PACKAGES A VENIR, JE VAIS METTRE DANSLE RMD QUAND J'AURAIS BIEN COMPRIS.




POUR APRES, RECHERCHER LES INFOS DE CE QUE SIGNIFIE LES utilisateur et systeme dans les resultats affichés. Comment choisir le nombre idéal de coeurs ? Y a t il meme une facon ? 