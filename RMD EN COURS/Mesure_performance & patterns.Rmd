---
title: "BROUILLON"
author: "Fogwoung Djoufack Sarah-Laure & Aissatou Sega Diallo"
date: "`r Sys.Date()`"
output: pdf_document
---

# PERFORMANCE ET ASPECTS PRATIQUES 

## Métriques de base 

### Speedup

Le speedup se définit comme le ratio du temps d'exécution d'une tâche en mode séquentiel (T₁) sur le temps en mode parallèle (Tₚ) :
$$
\text{Speedup} = \frac{T_1}{T_p}
$$
--- Speedup pour une tache légère (pour montrer que dans ce cas, le calcul parallele est plus couteux)

Ici on utilise une fonction qui calcule la somme des carrés des entiers de 1 à 10 000 suivant les methodes parallele et sequentielle. 

```{r speedup1, message=FALSE, warning=FALSE}
library(parallel)
library(tictoc)

# Fonction séquentielle
tache_sequentielle <- function(n = 1e4) {
  sum((1:n)^2)
}

# Fonction parallèle
tache_parallele <- function(n = 1e4, coeurs = 2) {
  cl <- makeCluster(coeurs)  # Création d'un cluster de travail avec un nombre spécifié de cœurs
  clusterExport(cl, varlist = "n")  # Exporter la variable 'n' dans les processus du cluster
  resultat <- parLapply(cl, split(1:n, cut(1:n, coeurs)), function(x) sum(x^2))  # Calcul parallèle des carrés, chaque sous-ensemble 'x' est traité sur un cœur
  stopCluster(cl)  # Arrêter le cluster une fois le calcul terminé
  Reduce("+", resultat)  # Agréger les résultats obtenus sur les différents cœurs
}

# Liste des cœurs à tester
liste_coeurs <- c(1, 2, 3, 4, 5, 6, 8)

# Initialisation du tableau des résultats
resultats_simples <- data.frame(Cœurs = liste_coeurs, Temps = NA, Speedup = NA)

# Temps de référence (séquentiel)
temps_seq <- system.time(tache_sequentielle())[3]

# Remplissage du tableau
for (i in seq_along(liste_coeurs)) {
  nb_coeurs <- liste_coeurs[i]
  
  if (nb_coeurs == 1) {
    resultats_simples$Temps[i] <- round(temps_seq, 4)
    resultats_simples$Speedup[i] <- 1
  } else {
    temps_par <- system.time(tache_parallele(1e4, nb_coeurs))[3]
    resultats_simples$Temps[i] <- round(temps_par, 4)
    resultats_simples$Speedup[i] <- round(temps_seq / temps_par, 2)
  }
}

# Affichage du tableau final
resultats_simples

```
En effet, on observe que la version séquentielle de la fonction prend environ 0,32 secondes, tandis que la version parallèle devient de plus en plus lente à mesure qu’on augmente le nombre de cœurs. Le tableau récapitulatif montre ainsi que le speedup est inférieur à 1 dans tous les cas, ce qui signifie qu’il n’y a aucun gain de performance – au contraire, l'exécution parallèle est plus lente. Cela s’explique par le coût de la création du cluster, de la répartition des données, et de la communication entre les cœurs, qui devient significatif face à une tâche aussi légère. Ces résultats montrent clairement que le parallélisme n’est pas avantageux pour les tâches simples. 

--- Speedup pour une tache complexe 

Produit matricielle de matrice de taille 1000*1000

Pour le calcul parallele, on donne des groupes de C_{ij} avec \[
C_{ij} = \sum_{k=1}^{n} A_{ik} \times B_{kj}
\] à différents coeurs pour les calculs. 

```{r speedup2, message=FALSE, warning=FALSE}
library(parallel)
library(tictoc)

# Fonction pour multiplier une sous-matrice (partie d'une matrice)
multiplication_matrice <- function(A, B, lignes, colonnes) {
  res <- matrix(0, nrow = length(lignes), ncol = length(colonnes))
  for (i in seq_along(lignes)) {
    for (j in seq_along(colonnes)) {
      res[i, j] <- sum(A[lignes[i], ] * B[, colonnes[j]])  # Produit scalaire des lignes et colonnes
    }
  }
  return(res)
}

# Fonction principale pour multiplier deux grandes matrices en parallèle
calcul_multiplication_parallele <- function(A, B, sections = 4) {
  n <- nrow(A)
  # Diviser les lignes et colonnes en sous-ensembles équilibrés
  lignes_par_section <- split(1:n, cut(1:n, sections, labels = FALSE))
  colonnes_par_section <- split(1:n, cut(1:n, sections, labels = FALSE))
  
  # Créer un cluster
  cl <- makeCluster(detectCores())  # Utilise tous les cœurs disponibles
  clusterExport(cl, varlist = c("A", "B", "multiplication_matrice"))  # Exporte seulement les variables nécessaires
  
  # Paralléliser la multiplication
  resultats <- parLapply(cl, 1:sections, function(i) {
    lignes <- lignes_par_section[[i]]
    colonnes <- colonnes_par_section[[i]]
    multiplication_matrice(A, B, lignes, colonnes)
  })
  stopCluster(cl)
  
  # Combiner les résultats dans la matrice finale
  matrice_resultat <- matrix(0, nrow = n, ncol = n)
  for (i in 1:sections) {
    lignes <- lignes_par_section[[i]]
    colonnes <- colonnes_par_section[[i]]
    matrice_resultat[lignes, colonnes] <- resultats[[i]]
  }
  
  return(matrice_resultat)
}

# Créer deux grandes matrices de taille 1000x1000
set.seed(123)
A <- matrix(rnorm(1000^2), nrow = 1000, ncol = 1000)
B <- matrix(rnorm(1000^2), nrow = 1000, ncol = 1000)

# Liste des sections et cores à tester
liste_coeurs <- c(1, 2, 3, 4, 5, 6, 8)
resultats_multiplication <- data.frame(Cœurs = liste_coeurs, Temps = NA, Speedup = NA)

# Calcul séquentiel de référence (temps pour la multiplication sans parallélisme)
temps_seq <- system.time({
  res_seq <- multiplication_matrice(A, B, 1:nrow(A), 1:ncol(B))
})[3]

# Remplissage du tableau des résultats
for (i in seq_along(liste_coeurs)) {
  nb_coeurs <- liste_coeurs[i]
  
  if (nb_coeurs == 1) {
    resultats_multiplication$Temps[i] <- round(temps_seq, 4)
    resultats_multiplication$Speedup[i] <- 1
  } else {
    temps_par <- system.time(calcul_multiplication_parallele(A, B, sections = nb_coeurs))[3]
    resultats_multiplication$Temps[i] <- round(temps_par, 4)
    resultats_multiplication$Speedup[i] <- round(temps_seq / temps_par, 2)
  }
}

# Affichage uniquement du tableau récapitulatif des résultats
print(resultats_multiplication)
```

### Efficacité

L'efficacité d'un calcul parallèle peut être définie comme le rapport entre le temps d'exécution séquentiel et le temps d'exécution parallèle, normalisé par le nombre de cœurs utilisés, et donc c'est égale au rapport du speedup sur le nombre de coeurs: 

\[
E = \frac{S}{N_{\text{coeurs}}} = \frac{T_{\text{par}} \times N_{\text{coeurs}}}{T_{\text{seq}}}
\]

En d'autres termes, l'efficacité mesure combien de travail parallèle chaque cœur accomplit. Plus l'efficacité est élevée, plus le calcul est optimal avec un nombre donné de cœurs. 

Tracons la courbe d'efficacité avec les valeurs obtenues precedemment. 

```{r efficace, message=FALSE, warning=FALSE}
# Données des résultats
cœurs <- c(1, 2, 3, 4, 5, 6, 8)
speedup <- c(1.00, 2.12, 2.47, 2.91, 3.15, 3.38, 3.61)

# Calcul de l'efficacité
efficacité <- speedup / cœurs

# Tracer la courbe d'efficacité
plot(cœurs, efficacité, type = "b", col = "blue", pch = 16, xlab = "Nombre de cœurs", ylab = "Efficacité", 
     main = "Courbe d'efficacité en fonction du nombre de cœurs")
grid()
```

Lorsque l'on utilise plusieurs cœurs pour effectuer un calcul parallèle, une partie du temps est consacrée à la gestion des cœurs et à la coordination entre eux. Cela inclut la création des clusters, où les données sont réparties entre les cœurs, et la synchronisation des résultats. Ce travail supplémentaire, bien qu'important pour que tout fonctionne correctement, ne contribue pas directement à l'exécution du calcul lui-même. Plus on ajoute de cœurs, plus cette gestion devient coûteuse en temps, ce qui réduit l'efficacité de l'ensemble du processus et limite les gains attendus.

Cela illustre bien la nécessité d'optimiser le nombre de cœurs utilisés en fonction de la tâche.

### Loi d’Amdahl (limite théorique du parallélisme).

### Loi de Gustafson (adaptation à l’échelle des données).

## Défis et optimisation

Différents défis affectent l'efficacité de la parallélisation. 

### a. Overhead

L'**overhead** (ou surcharge) fait référence à la quantité de travail supplémentaire introduite lors de l'utilisation du parallélisme. Bien que l'idée soit de répartir le travail sur plusieurs cœurs pour accélérer l'exécution, il y a souvent des coûts associés à la gestion de cette parallélisation.

#### Exemples d'overhead :

- **Diviser le travail** : Lorsque le travail est partagé entre les cœurs, une certaine quantité de temps est nécessaire pour diviser les tâches et les distribuer.
- **Gestion de la mémoire** : Il faut souvent allouer et gérer de la mémoire pour chaque cœur, ce qui peut entraîner une surcharge supplémentaire.
- **Communication entre les cœurs** : Si les différents cœurs doivent partager des informations ou combiner leurs résultats, cela peut ralentir le processus global, car les cœurs doivent attendre pour s'échanger ces données. 

#### Comment l'optimiser ?

- **Optimiser la taille des tâches** :  Si une tâche est trop petite, la gestion de cette petite tâche prend plus de temps que l'exécution elle-même, ce qui augmente l'overhead. Il faut trouver un bon équilibre dans la taille des tâches.

- **Utilisation d'algorithmes parallèles efficaces** : Choisir des algorithmes conçus pour minimiser l'overhead, comme ceux qui nécessitent moins de communication entre les cœurs.

### b. Problèmes de Synchronisation

Les **problèmes de synchronisation** surviennent lorsqu'il y a des dépendances entre les tâches qui nécessitent que certains processus attendent l'achèvement des autres avant de pouvoir poursuivre. Ce phénomène peut entraîner des retards importants et une perte d'efficacité dans un système parallèle.

#### Exemples de problèmes de synchronisation :

- **Attente des résultats** : Si une tâche dépend des résultats d'une autre tâche, les cœurs doivent attendre la fin de la tâche précédente avant de continuer, ce qui peut ralentir l'ensemble du processus.
- **Deadlock (verrouillage mutuel)** : Un état où deux ou plusieurs tâches sont en attente indéfinie les unes des autres, ce qui arrête complètement le programme.
- **Race conditions (conditions de concurrence)** : Des erreurs peuvent se produire si plusieurs cœurs essaient de modifier la même donnée en même temps sans coordination, ce qui peut entraîner des résultats incorrects.

#### Comment l'optimiser ?

- **Utiliser des mécanismes de synchronisation efficaces**  pour contrôler l'accès aux ressources partagées.
- **Réduire les dépendances** : Concevoir les algorithmes de manière à minimiser les tâches dépendantes les unes des autres, de sorte que les cœurs puissent fonctionner de manière plus indépendante.
- **Optimiser la granularité des tâches** : Parfois, diviser les tâches en morceaux plus petits et indépendants permet de réduire les attentes liées à la synchronisation.

### c. Stratégies : Taille des Tâches, Choix du Nombre de Workers

Les stratégies d'optimisation se concentrent sur deux éléments clés : la **taille des tâches** et le **choix du nombre de workers** (cœurs ou threads utilisés).

#### Taille des Tâches

- **Trop petite** : Une tâche trop petite peut entraîner un overhead élevé à cause de la gestion de la tâche et de la synchronisation.
- **Trop grande** : Si une tâche est trop volumineuse et est attribuée à un seul cœur ou à un nombre limité de cœurs, les autres cœurs qui pourraient être utilisés pour traiter différentes parties du travail restent inactifs ou sous-utilisés. Cela entraîne des périodes d'attente inutiles pour ces cœurs, qui attendent que le cœur principal termine sa portion de travail. Ce déséquilibre dans l'utilisation des ressources réduit l'efficacité globale du système.

**Optimisation** : Il est important de trouver une taille de tâche optimale qui permet à chaque cœur de travailler efficacement tout en minimisant l'overhead de gestion.

#### Choix du Nombre de Workers (Cœurs/Threads)

- **Trop de workers** : Trop de workers peuvent entraîner une concurrence excessive pour les ressources, un conflit de cache et un overhead de communication.
- **Trop peu de workers** : Trop peu de workers peuvent ne pas exploiter pleinement les ressources disponibles.

**Optimisation** : Il est crucial de choisir le nombre de workers en fonction du problème à résoudre et du nombre de cœurs disponibles. Idéalement, le nombre de workers devrait être en accord avec la taille du problème et la capacité de calcul du système.

## Patterns essentiels 

### 1. Fork-join

**Principe :**  
On découpe une tâche en plusieurs sous‑tâches indépendantes (fork), on exécute ces sous‑tâches simultanément sur plusieurs cœurs, puis on combine (join) leurs résultats pour produire la réponse finale.

**Étapes :**  
1. **Fork** : création de sous‑tâches à partir de la tâche principale.  
2. **Exécution parallèle** : chaque sous‑tâche s’exécute sur un cœur distinct.  
3. **Join** : agrégation des résultats partiels pour reconstituer la solution complète.  

`![Texte alternatif](../IMAGE RMD/fork join.png)

```{r fork-join, echo=TRUE, message=FALSE, warning=FALSE}
# Tâche principale : additionner quatre vecteurs de 1e6 nombres
vec_list <- list(rnorm(1e6), rnorm(1e6), rnorm(1e6), rnorm(1e6))

# Fork-Join
n_cores <- 4
cl <- makeCluster(n_cores)

# Fork : on distribue chaque vecteur à un cœur
results <- parLapply(cl, vec_list, function(v) sum(v))

# Join : on additionne les sommes partielles
total_sum <- Reduce("+", results)

stopCluster(cl)
total_sum
```

### 2. Divide & Conquer

**Principe :**  
On résout un problème en le divisant **récursivement** en sous‑problèmes plus petits, jusqu’à ce qu’ils soient assez simples pour être résolus directement. Ensuite, on **combine** les solutions de ces sous‑problèmes pour obtenir la solution du problème initial.

**Étapes :**  
1. **Diviser** : séparer le problème en deux (ou plusieurs) sous‑problèmes de taille réduite.  
   - *Aucun tri n’est effectué à cette étape*, on ne fait que découper la liste.  
2. **Conquer (Régner)** : résoudre chaque sous‑problème, éventuellement en réappliquant récursivement la même méthode, jusqu’à obtenir des sous‑listes de taille 1 (déjà triées).  
3. **Combiner** : fusionner les solutions des sous‑problèmes pour former la solution finale.  

`![Texte alternatif](../IMAGE RMD/Divide_conquer.jpeg)

### 3. Map Reduce

Le modèle MapReduce est utilisé pour traiter de grandes quantités de données en parallèle, c'est-à-dire en les traitant simultanément, mais de manière organisée. Il consiste en 4 étapes principales : Division des données, Map, Shuffle (Regroupement) et Reduce.

`![Texte alternatif](../IMAGE RMD/Map_reduce.png)

**Étapes :**

1. **Division des données ** : Dans la phase de division, les données sont découpées en morceaux plus petits, pour un traitement plus rapide et facile. 

2. **Map ** : Une fois les données découpées, la phase Map entre en jeu. La fonction Map est appliquée à chaque morceau de données. Elle prend un morceau en entrée, le traite et génère des paires clé-valeur.La clé peut être n'importe quel identifiant ou valeur qui représente un élément spécifique du morceau de données. Par ailleurs, la valeur est un nombre qui représente l'information associée à cette clé. Dans beaucoup de cas, cette valeur est simplement un nombre 1, pour signifier que l'élément a été trouvé ou observé une fois. 

3. **Shuffle **: Une fois les paires clé-valeur générées, il est temps de les regrouper pour les préparer à la phase Reduce. Elle consiste à regrouper toutes les paires ayant la même clé ensemble.

4. **Reduce **: La phase Reduce consiste à agréger les données regroupées par la phase Shuffle. Pour chaque groupe de paires ayant la même clé, une fonction Reduce est appliquée pour combiner ou résumer les valeurs.

**Exemple 1 :** Comptage des fréquences de chaque mot dans un texte 

```{r map-reduce1, echo=TRUE, message=FALSE, warning=FALSE}

# Texte à analyser (exemple simple)
phrases <- c(
  "Le chat mange le poisson",
  "Le chien court après le chat",
  "Le poisson nage dans l'eau"
)

# --- Phase MAP ---
map_function <- function(phrase) {
  # Découpage de la phrase en mots (clés)
  mots <- unlist(strsplit(tolower(phrase), "\\W+"))  # Ignorer la casse et la ponctuation
  # Génération des couples (mot, 1)
  return(data.frame(mot = mots, valeur = 1))
}

# --- Phase REDUCE ---
reduce_function <- function(cles, valeurs) {
  # Agrégation : somme des valeurs par clé
  aggregate(valeur ~ mot, data = data.frame(mot = cles, valeur = valeurs), sum)
}

# Configuration du cluster (4 cœurs)
cl <- makeCluster(4)
clusterExport(cl, c("map_function", "reduce_function"))

# --- MAP ---
# Appliquer la fonction map à chaque phrase en parallèle
resultats_map <- parLapply(cl, phrases, map_function)

# --- SHUFFLE (Regroupement des clés) ---
# Combiner tous les résultats partiels
donnees <- do.call(rbind, resultats_map)

# --- REDUCE ---
# Appliquer la fonction reduce sur les données groupées
resultat_final <- reduce_function(donnees$mot, donnees$valeur)

# Arrêt du cluster
stopCluster(cl)

print(resultat_final)

```

**Exemple 2 :** Avec les données sattelites 